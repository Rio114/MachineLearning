= まえがき

本書を手に取っていただきありがとうございます。
本書は機械学習の中でもポピュラーな二値分類について取り上げます。
と言っても、どのようなモデルやアルゴリズムを使うとバシッと二つに分けられるかといったことは語りません。
最先端のアルゴリズムを追いかける前に、それらの良し悪しを判断できるようになろう、というのが本書の第一のテーマです。
具体的には二値分類モデルを評価するにあたって以下のような課題を感じている方に読んでいただければと思っています。

 * RecallとPrecisionっていつも混乱するんだよな。
 * そもそも、RecallとPrecisionってどうやって使い分けたらいいの。
 * AUCは0.7~0.8くらいで良いんだよね。
 * ROC曲線で何を判断していいかわからない。
 * 二値分類なんてLightGBMにぶち込めばいいんでしょ。
 * LighGBMの予測値って確率値なんだよね。

二値分類は問題としてはシンプルですが、現実問題に当てはめると0か1かで判断できるようなことは限られていて、グレーゾーンの中で良し悪しを決めなくてはならないことばかりです。
また、最近ではPythonでLightGBMのライブラリを使えばシグマ記号だらけの理論を理解することなく簡単に良い感じの二値分類モデルを作ることができます。
しかし、それでもそのアウトプットが使い物になるかはわかりません。

もう一つのテーマは不均衡なデータであるということです。
不均衡な二値分類とは、何か特別なものをその他大勢から見つけ出すという作業になります。
病気の発見であったり、見込み客の絞り込みであったりと二値分類の応用の殆どは不均衡データであると言っても過言ではありません。
そのような状況で二値分類をどう読み解いていったらよいかというのが第二のテーマです。

本書では四則演算程度の数式は出てきますが、シグマ記号や微分積分は出てきません。
それよりも簡単な数式でも頭の中でイメージできることが大事かと思います。
例えば割合だったら、何が全体でその中の何を見ているのか、といったことです。

イメージを追いながら数字を一つ一つ理解していくと、顧客属性に応じた広告の出し分けみたいなこともブラックボックス化せずにできるようになります。
ただし、LightGBMの中身は本書では割愛します。

というわけで、AUCは0.7~0.8ぐらいでいいんじゃね、というレベルから一段上の理解を目指して最後までお付き合いいただけると幸いです。
