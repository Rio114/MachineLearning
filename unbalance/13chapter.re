= 二値分類モデルのキャリブレーション

== 二値分類モデルのキャリブレーション

前章の二値分類モデルの評価では、ROCでもRPでもスコアの順序が正例である可能性の高さの順序になっているかを確認するものであることを見た。
しかし、それだけでなく、予測値がそのまま確率値になっていると何かと都合が良い。
例えば、あるユーザに対して二つのうち一つのサービスを訴求するとき、それぞれのサービス加入予測モデルを使ってスコアの高い方を訴求するということを考える。
このとき、両方のモデルから得られるスコアがそのまま予測値を示していると、単純にスコアの高い方を訴求すればそのまま加入確率の高いサービスを訴求することになる。
しかし、スコアのキャリブレーションが不十分で予測値の大小と加入確率の大小で逆転している場合、予測値の大きい方を選択すると実は加入確率が低い方を選択してしまっていたということが起こりうる。
この状況を表したのが次の相関図である。
この相関図は各サービスの予測値と、その予測値をもつデータ集合の正例の割合をプロットしたものである。
サービスAとサービスBでは傾きが異なっているため、あるユーザに対しては予測値の大小と正例割合の大小が逆転していることが起こりうる。
二値分類モデルごとに学習度合いが異なるとこういったことが起こりやすいため予測値のキャリブレーションが必要になる。

//image[corr][予測値と正例割合の相関図][scale=0.7]{
//}

== スコア散布図
ROCやRPはスコア順にデータ点を並べて集計することにより作った。つまり、スコアの絶対値は評価されていない。しかし、二値分類スコアそのものがどの程度、正例を予測しているかという、スコアの絶対値に興味がある場合がある。それぞれのデータ点は0か1のいずれかであり、x軸にスコア、y軸に正負をそのままプロットしても解釈が難しい。そこで、スコアの近いものをまとめて（例えば、0.01刻みで層別化する）、正負の0－1フラグの平均を代表させることで、スコアが二項分布の確率母数を表すと解釈する。そのようにスコアと予測確率を一対一に対応させることができれば、例えば異なるモデル間でスコアを比較し、その大小で判断を行うようなバンディット問題に応用できる。これを散布図としてプロットすれば視覚的にモデルの良し悪しを検証できる。


=== 予測値の分布と散布図
予測値の分布は、正例と負例で分けることができる。

正例の予測値分布と負例の予測値分布を、予測値でビンに区切って割合を計算することで

*書き方の図示*



=== logloss
異なるモデル間でのスコアの比較を考えると、同じスコアは同じ予測確率を示すことが前提となる。それは散布図では同一のグラフに乗ることを意味しており、特に数値の解釈性の観点から、斜め45度の直線に乗るようなスコア＝予測確率となることが望ましい。

都合の良いことに、説明変数が同じでスコアが同一になると考えられる集団があったとすると、二項分布の最尤推定を行うことでスコア＝予測確率となる。これは形式的にはloglossを最小化することと同等である。二値分類予測の損失関数としてloglossが用いられることが多いのはこういった理由がある。

*y=0, 1のそれぞれに点が集まっている図*

*y=0, 1のそれぞれに点が集まっている図、あるスコアで層別したときに割合を計算する図*

== 評価例
冒頭で挙げたモデルに対して、それぞれのモデル評価がどのようになるかを見比べたい。


== ベータ分布
予測分布はベータ分布に近いように見える。

 * 確率変数が0から1の範囲である。
 *

正例負例の予測分布をそれぞれパラメトリックに表現できれば、予測値に対して正負両方の確率密度から正負の割合を計算することができる。
この割合を新たな予測値とすると、
