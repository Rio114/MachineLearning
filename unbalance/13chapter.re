= 二値分類モデルの予測値

== 予測値と正例の割合

前章の二値分類モデルの評価では、ROCでもRPでもスコアの順序が正例である可能性の高さの順序になっているかを確認するものであることを見た。
しかし、それだけでなく、予測値がそのまま確率値になっていると何かと都合が良い。
例えば、あるユーザに対して二つのうち一つのサービスを訴求するとき、それぞれのサービス加入予測モデルを使ってスコアの高い方を訴求するということを考える。
このとき、両方のモデルから得られるスコアがそのまま予測値を示していると、単純にスコアの高い方を訴求すればそのまま加入確率の高いサービスを訴求することになる。
しかし、スコアのキャリブレーションが不十分で予測値の大小と加入確率の大小で逆転している場合、予測値の大きい方を選択すると実は加入確率が低い方を選択してしまっていたということが起こりうる。
この状況を表したのが次の相関図である。
この相関図は各サービスの予測値と、その予測値をもつデータ集合の正例の割合をプロットしたものである。
サービスAとサービスBでは傾きが異なっているため、あるユーザに対しては予測値の大小と正例割合の大小が逆転していることが起こりうる。
二値分類モデルごとに学習度合いが異なるとこういったことが起こりやすいため予測値のキャリブレーションが必要になる。

//image[corr][予測値と正例割合の相関図][scale=0.7]{
//}

== 相関図の原理

二値分類モデルによる予測値の出力は多くの場合で0から1の範囲で与えられる。
もし予測値がこの範囲を超えていても、線形な変換で順序を変えずに0から1に限定することができるとする。
一方、目的変数は正例なら1、負例なら0であるとする。
これにより、データ全体の目的変数の平均は正例の割合と一致する。

次の図のように予測値を分布（ヒストグラム）を考えると、正例か負例か、目的変数が1か0かで二つの分布を考えることができる。

//image[predict_hist][予測値の分布][scale=0.7]{
//}

ヒストグラムを重ねて表示することにより相関図の意味がより鮮明になる。
すなわち、同じ予測値における正例と負例の確率密度の比が正例の割合となる。

次の図では、ヒストグラムから相関図が得られる様子を示している。
正例の予測値の最小値より小さい予測値に対しては、全てのデータは負例である。
すなわち、その範囲の予測値のもとでは、正例割合は0である。
一方、負例の予測値の最大値よりも大きい予測値のもとでは、正例割合は1である。
そして、予測値が正例の予測値の最小値と負例の予測値の最大値の間にある場合は確率密度の比に従って正例割合が決まる。

//image[corr_hist][予測値の分布と相関図][scale=0.7]{
//}

正例負例の予測値の分布がそれぞれパラメトリックに数式で得られる場合、訓練データに含まれない説明変数でも確率密度を計算してその割合を見積もることができる。
また、確率密度から見積もった割合と、正解から得られる正例割合を比較するとモデルから直接得られる値よりも近いと期待される。
つまり、予測値が確率値としてキャリブレーションできたことになる。
テストデータに対してもこのようなことを行えば、確率値にキャリブレーションされた予測値を得ることができる。

=== グラフィカルモデルによる説明
上記の説明をグラフィカルモデルに落とし込むと次の図のようになる。

//image[graph][確率値にキャリブレーションされた予測値を得るグラフィカルモデル][scale=0.7]{
//}

//table[params_graph][グラフィカルモデルのパラメータ]{
シンボル	名称	説明
------------
X、X'	説明変数	二値分類モデルに投入する変数
T、T'	目的変数	二値分類の正解ラベル。正例：１、負例：０
M	二値分類モデル	LightGBMやLogistic回帰などの二値分類モデル
S、S'	二値分類予測値	二値分類モデルによって得られる予測値
C	予測値分布パラメータ	正例負例それぞれの予測値分布を記述するパラメータ
Y、Y'	正例割合予測	二値分類モデル予測値に応じた正例割合の予測値
//}

==== データセット
入力となるデータセットである。
X'、T'は二値分類モデルの学習前に分けたテストデータである。

//image[dataset][データセット][scale=0.3]{
//}

==== 二値分類モデル学習
説明変数Xと目的変数Tにより二値分類モデルMを学習する。

//image[train_model][モデル学習][scale=0.3]{
//}

==== 予測値算出
説明変数Xと二値分類モデルMにより二値分類の予測値Sを算出する。
モデルMを用いてテスト用データのX'からS'も算出できる。

//image[cal_score][予測値算出][scale=0.3]{
//}

==== 予測値分布パラメータ算出
二値分類予測値Sと目的変数Tにより予測値分布のパラメータCを算出する。

//image[cal_param][予測分布パラメータ算出][scale=0.3]{
//}

==== 正例割合算出
二値分類予測値SとパラメータCにより、予測値Sに応じた正例割合Yを算出する。

Y = N_pos * Dist_pos / (N_pos * Dist_pos + N_neg * Dist_neg)

//table[Dist_fit][正例割合算出での変数]{
シンボル	名称
------------
N_pos	訓練データの正例の数
N_neg	訓練データの負例の数
Dist_pos	正例に対する予測値Sでの確率密度
Dist_neg	負例に対する予測値Sでの確率密度
//}

正例負例それぞれの予測値分布について、パラメータCによる分布と実際の分布の当てはまりが良ければ、最終的にTとYは近い値になっているはずである。
パラメータCをそのままで、テストデータの予測値S'から正例割合Y'を算出することができる。
もしテストデータの正解T'がわからなくても、X'からY'を算出し、TとYの関係からT'の予測を行うことができる。

//image[cal_ratio][正例割合算出][scale=0.3]{
//}

上記の手法で、訓練データXから二値分類モデルと予測値分布の二段階で正例の割合を予測することができる。
もちろん、それぞれの段階で過学習の問題があるので、モデリングを多く挟む分精度や信頼性が失われていると考えられるが、予測値を確率値として補正した代償だと言える。
どの程度の精度低下が起こるかは訓練データとテストデータの比較によって相対的に評価する。

== logloss
異なるモデル間でのスコアの比較を考えると、同じスコアは同じ予測確率を示すことが前提となる。それは散布図では同一のグラフに乗ることを意味しており、特に数値の解釈性の観点から、斜め45度の直線に乗るようなスコア＝予測確率となることが望ましい。

都合の良いことに、説明変数が同じでスコアが同一になると考えられる集団があったとすると、二項分布の最尤推定を行うことでスコア＝予測確率となる。これは形式的にはloglossを最小化することと同等である。二値分類予測の損失関数としてloglossが用いられることが多いのはこういった理由がある。

== 評価例
前章のSantanderの例で、予測値のフィッティングを行ってみる。

=== 予測分布の視覚化
予測値を正例負例に分けて分布を視覚化すると以下のようになる。
この分布は確率変数が0から1の範囲に限定されていて、形状はベータ分布によく当てはまりそうに見える。

＊予測値分布＊

=== ベータ分布による正例割合のフィッティング
ベータ分布の母数はalpha, betaであるがこれは分布の平均と分散から連立方程式を解くことで求められる。
母数は正例負例それぞれについて計算する。

e = a / (a+b)
v = ab / (a+b)^2 / (a+b+1)

a = e^2 (1-e) / v - e
b = (1-e) / e * a

ベータ分布は数式によりパラメトリックに算出できるので、ある予測値Sにおける正例の予測割合は次のように計算できる。

Y = N_pos * Beta_pos / (N_pos * Beta_pos + N_neg * Beta_neg)

//table[beta_fit][ベータ分布フィッティングの変数]{
シンボル	名称
------------
e	予測分布の平均
v	予測分布の分散
a	ベータ分布の母数１
b	ベータ分布の母数２
N_pos	訓練データの正例の数
N_neg	訓練データの負例の数
Beta_pos	正例に対する、母数a,b、予測値Sでの確率密度
Beta_neg	負例に対する、母数a,b、予測値Sでの確率密度
//}
